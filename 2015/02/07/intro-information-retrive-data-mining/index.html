<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"/>




  <link href="//fonts.useso.com/css?family=Lato:300,400,700,400italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">



<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=0.5.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=0.5.0" />






<meta name="description" content="IntroductionInformation retrieval: obtained relevant information by searching through large scale unstructured data; Data mining: extract knowledge, insights and useful information by mining the obtai">
<meta property="og:type" content="article">
<meta property="og:title" content="Information Retrive Data Mining">
<meta property="og:url" content="http://yoursite.com/2015/02/07/intro-information-retrive-data-mining/index.html">
<meta property="og:site_name" content="Paprika">
<meta property="og:description" content="IntroductionInformation retrieval: obtained relevant information by searching through large scale unstructured data; Data mining: extract knowledge, insights and useful information by mining the obtai">
<meta property="og:image" content="http://yoursite.com/pictures/inverted_index.png">
<meta property="og:image" content="http://yoursite.com/pictures/inverted_index_count.png">
<meta property="og:image" content="http://yoursite.com/pictures/inverted_index_position.png">
<meta property="og:updated_time" content="2016-03-09T07:41:18.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Information Retrive Data Mining">
<meta name="twitter:description" content="IntroductionInformation retrieval: obtained relevant information by searching through large scale unstructured data; Data mining: extract knowledge, insights and useful information by mining the obtai">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: 'Author'
    }
  };
</script>

  <title> Information Retrive Data Mining | Paprika </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Paprika</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-algorithm">
          <a href="/categories/Algorithm/" rel="section">
            
            algorithm
          </a>
        </li>
      
        
        <li class="menu-item menu-item-introduction">
          <a href="/categories/Introduction/" rel="section">
            
            introduction
          </a>
        </li>
      
        
        <li class="menu-item menu-item-developing logs">
          <a href="/categories/Developing-Logs/" rel="section">
            
            developing logs
          </a>
        </li>
      
        
        <li class="menu-item menu-item-programming skills">
          <a href="/categories/Programming-Skills/" rel="section">
            
            programming skills
          </a>
        </li>
      
        
        <li class="menu-item menu-item-machine learning">
          <a href="/categories/Machine-Learning/" rel="section">
            
            machine learning
          </a>
        </li>
      
        
        <li class="menu-item menu-item-math">
          <a href="/categories/Math/" rel="section">
            
            math
          </a>
        </li>
      
        
        <li class="menu-item menu-item-statistic">
          <a href="/categories/Statistic/" rel="section">
            
            statistic
          </a>
        </li>
      
        
        <li class="menu-item menu-item-python">
          <a href="/tags/Python/" rel="section">
            
            python
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Information Retrive Data Mining
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2015-02-07T13:05:07+08:00" content="2015-02-07">
              2015-02-07
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Introduction/" itemprop="url" rel="index">
                    <span itemprop="name">Introduction</span>
                  </a>
                </span>

                
                
                  , 
                

              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Introduction/Data-Mining/" itemprop="url" rel="index">
                    <span itemprop="name">Data Mining</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>Information retrieval: obtained relevant information by searching through large scale unstructured data; Data mining: extract knowledge, insights and useful information by mining the obtained relevant information.</p>
<p>IR (data -&gt; relevant information), DM (relevant information -&gt; patterns and knowledge)</p>
<p>Data Mining tasks (machine learning):</p>
<ul>
<li>Classification</li>
<li>Clustering</li>
<li>Regression</li>
</ul>
<p>Unique data mining tasks:</p>
<ul>
<li>Association Rule Discovery</li>
<li>Outlier (Anomaly) Detection</li>
<li>User intersts Mining</li>
</ul>
<a id="more"></a>
<h4 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h4><p>Precision and Recall are two widely used measures for evaluating the quality of retrieval results.</p>
<p>Precision is the number of relevant documents retrieved divided by the total number of documents retrieved.</p>
<p>Recall is the number of relevant documents retrieved divided by the total number of existing relevant documents.</p>
<h4 id="Retrieval_Models"><a href="#Retrieval_Models" class="headerlink" title="Retrieval Models"></a>Retrieval Models</h4><p>A retrieval model abstracts away from the real world, it is a mathematical representation of the essentil aspects of a retrieval system, it aims at computing the relevance and retrieving relevant documents. Thus, either explicitly or implicitly, defines relevance.</p>
<h5 id="Exact_Matching_3A_data_retrieval"><a href="#Exact_Matching_3A_data_retrieval" class="headerlink" title="Exact Matching: data retrieval"></a>Exact Matching: data retrieval</h5><p>Query specifies precise retrieval criteria, every document either matches or fails to match query. The result is relevance or non-relevance.</p>
<p>Pros: offer user great control. Cons: too many or too few results and unordered output.</p>
<h5 id="Best_Match/Rank_Retrieval"><a href="#Best_Match/Rank_Retrieval" class="headerlink" title="Best Match/Rank Retrieval"></a>Best Match/Rank Retrieval</h5><p>Query describes retrieval criteria for desired documents, every document matches a query to some degree. Result is a ranked list of documents on the basis of either probability of relevance or degraded relevance. Web search is ranked retrieval.</p>
<p>Pros: easy to use. Cons: query less precise.</p>
<h5 id="Boolean"><a href="#Boolean" class="headerlink" title="Boolean"></a>Boolean</h5><h5 id="Extended_Boolean"><a href="#Extended_Boolean" class="headerlink" title="Extended Boolean"></a>Extended Boolean</h5><h5 id="TF_IDF_Term_weighting"><a href="#TF_IDF_Term_weighting" class="headerlink" title="TF IDF Term weighting"></a>TF IDF Term weighting</h5><h5 id="Vector_Space_Model"><a href="#Vector_Space_Model" class="headerlink" title="Vector Space Model"></a>Vector Space Model</h5><h5 id="Basic_Probabilistic_Model"><a href="#Basic_Probabilistic_Model" class="headerlink" title="Basic Probabilistic Model"></a>Basic Probabilistic Model</h5><h5 id="Two_Poisson_Mode_-_BM25"><a href="#Two_Poisson_Mode_-_BM25" class="headerlink" title="Two Poisson Mode - BM25"></a>Two Poisson Mode - BM25</h5><h5 id="Bayesian_Inference_Networks"><a href="#Bayesian_Inference_Networks" class="headerlink" title="Bayesian Inference Networks"></a>Bayesian Inference Networks</h5><h5 id="Statistical_Language_Models"><a href="#Statistical_Language_Models" class="headerlink" title="Statistical Language Models"></a>Statistical Language Models</h5><h5 id="Portfolio_Retrieval"><a href="#Portfolio_Retrieval" class="headerlink" title="Portfolio Retrieval"></a>Portfolio Retrieval</h5><h5 id="Citation_Analysis_Models"><a href="#Citation_Analysis_Models" class="headerlink" title="Citation Analysis Models"></a>Citation Analysis Models</h5><p>Hubs &amp; authorities</p>
<p>PageRank</p>
<h3 id="Web_Serach_via_Link_Analysis"><a href="#Web_Serach_via_Link_Analysis" class="headerlink" title="Web Serach via Link Analysis"></a>Web Serach via Link Analysis</h3><h4 id="Relevance_Rank"><a href="#Relevance_Rank" class="headerlink" title="Relevance Rank"></a>Relevance Rank</h4><p>look at the hyperlinks between URLs to infer their relevancies, applications areas: web, email, social networks.</p>
<p>The web is a directed graph, two assumptions:</p>
<ul>
<li>A hyperlink between pages denotes a conferral of authority (quality signal)</li>
<li>The text in the anchor of the hyperlink describes the target page (textual context)</li>
</ul>
<p>document text + anchor text is often more effective than searching on document test only. like search for IBM homepage.</p>
<ul>
<li>Anchor text can be weighted more highly than document text; or can score anchor text with weight depending on the authority of the anchor page’s website.</li>
<li>Side effects: google bombs. maliciously manipulated anchor text.<br>look at the content/texts of documents to infer their relevancies</li>
</ul>
<h4 id="PageRank"><a href="#PageRank" class="headerlink" title="PageRank"></a>PageRank</h4><p>Co-citation similarity: measure the similarity of two articles by the overlap of other articles citing them.</p>
<h4 id="HITS"><a href="#HITS" class="headerlink" title="HITS"></a>HITS</h4><p>Hyperlink-Induced Topic Search Model: best suited for “board topic” queries rather than for page-finding queries.</p>
<p>Intersting documents fall into two classes:</p>
<ul>
<li>Authorities: pages containing useful information (home page)</li>
<li>Hubs: pages that link to authorities.</li>
</ul>
<p>Good hub links to many good authorities, good authorities is linked from many good hubs. This circular definition will turn into an iterative computation.</p>
<p>In response to a query, instead of an ordered list of pages each meeting the query, find two sets of inter-related pages: hub pages and authority pages.</p>
<p>How to form a base case?</p>
<p>Given text query use a text index to get all pages contining that text query, called root set. Add in any page that either points to a page in the root set or is pointed to by a page in the root set.</p>
<h3 id="Text_Procesing_and_Indexing"><a href="#Text_Procesing_and_Indexing" class="headerlink" title="Text Procesing and Indexing"></a>Text Procesing and Indexing</h3><h4 id="Text_Acquisition_3A_Web_Crawler"><a href="#Text_Acquisition_3A_Web_Crawler" class="headerlink" title="Text Acquisition: Web Crawler"></a>Text Acquisition: Web Crawler</h4><p>Finds and downloads web pages automatically, provides the collection for searching.</p>
<p>Web is huge and constantly grouwing.</p>
<p>Web is not under the control of search engine providers, web pages are constantly changing.</p>
<p>Need to re-crawl regularly.</p>
<p>How web crawler work?</p>
<p>Starts with a set of seeds, which are a set of URLs given to it as parameters. Seeds are added to a URL request queue. Crawler starts fetching pages from the request queue. Downloaded pages are parsed to find link tags that might contain other useful URLs to fetch. New URLs added to the crawler’s request queue/frontier, Continue until no more new URLs or disk full.</p>
<p>Web crawlers spend a lot of time waiting for responses to requests, to reduce this inefficiency, web crawlers use threads and fetch hundreads of pages at once. Crawlers could pontentially flood sites with requests for pages, to avoid this, politeness policies are adopted. For instance, delay between requests to same web server.</p>
<h4 id="Text_Transformation_3AProcessing_Text"><a href="#Text_Transformation_3AProcessing_Text" class="headerlink" title="Text Transformation:Processing Text"></a>Text Transformation:Processing Text</h4><p>This process converts documents to index terms. Why?</p>
<ul>
<li>mathcing the exact string of chars tuped by user is too restricitve.</li>
<li>not all words are of equal value in a search</li>
<li>sometimes not clear where words begin and end (Chinese)</li>
</ul>
<p>Parser: processing the sequnce of text tokens in the document to recognize structural elements. (titles, links, headings)</p>
<p>Tokeniser recognizes “words” in the text must consider issues like capitalization, hyphens (the mark - to join two words into one), apostrophes (eg: what’s), non-alpha characters, separators.</p>
<p>Document parder uses syntax of markup language (or other formatting) to identify structure.</p>
<p><strong>Tokenizing</strong> Forming words from sequence of characters</p>
<h5 id="Stopping"><a href="#Stopping" class="headerlink" title="Stopping"></a>Stopping</h5><p>Stopping is to remove common words like “and”, “or”, “then”, “in”. Some impact on efficiency and effectiveness. Can be a problem for some queries.</p>
<h5 id="Stemming"><a href="#Stemming" class="headerlink" title="Stemming"></a>Stemming</h5><p>Group words derived from a common stem, “computers”, “computing”. Usually effective, but not for all queries. Benefits vary for different languages.</p>
<p>Stemming has two basic types:</p>
<ul>
<li>dictionary-based: uses lists of related words</li>
<li>algorithmic: uses program to determine related words. eg: suffix-s: remove ‘s’ ending assuming plural. cats -&gt; cat, ups -&gt; up (wrong)</li>
</ul>
<p>Porter Stemmer</p>
<ul>
<li>consists of a series of rules designed to the longest possible suffix at each step</li>
<li>effective in TREC</li>
<li>drawback: makes a number of errors and difficult to modify</li>
</ul>
<h5 id="Link_Analysis"><a href="#Link_Analysis" class="headerlink" title="Link Analysis"></a>Link Analysis</h5><p>makes use of links and anchor text in web pages, identifies popularity and community information (PageRank)</p>
<h4 id="Index_Creation"><a href="#Index_Creation" class="headerlink" title="Index Creation"></a>Index Creation</h4><p>Indexes are data structure designed to make search faster. Text search has unique requirements, which leads to unique data structres. Most common data structure is <em>inverted index</em>, “inverted” cause documents are associated with words, rather than words with documents.</p>
<p>Inverted Index: each index item is associated with an inverted list, contains lists of documents, or lists of word occurrences in documents, and other information. Each entry is called a posting. The part of the posting that refers to a specific document or location is called a pointer. Each document in the collection is given a unique number. Lists are usually document-orderedd (sort by document number).</p>
<p>Example: four sentences from the Wikipedia entry for tropical fish.</p>
<pre><code>$S_1$: Tropical fish include fish found in tropical environmnets around the world, in cluding both freshwater and salt water species.
$S_2$: Fishkeepers often use the term tropical fish to refer only those requiring fresh water, with saltwater tropical fish referred to as marine fish.
$S_3$: Tropical fish are popular aquarium fish, due to their often bright coloration.
$S_4$: In freshwater fish, this coloraion typically derives from iridescence, while salt water fish are generally pigmented.
</code></pre><p><img src="/pictures/inverted_index.png" alt=""></p>
<p><img src="/pictures/inverted_index_count.png" alt=""></p>
<p><img src="/pictures/inverted_index_position.png" alt=""></p>
<h4 id="Compression"><a href="#Compression" class="headerlink" title="Compression"></a>Compression</h4><h5 id="Entropy"><a href="#Entropy" class="headerlink" title="Entropy"></a>Entropy</h5><p>inverted lists are very large, (bigrams used most even larger). Lossless compression algorithm vs. lossy compression (suitable for text, in vedio not that good)</p>
<p>Text Compression: used to compress vocabulary, document names, original document text. Based on assumptions about language.</p>
<p>Data Compression: Used to compress inverted lists. Not generally based on assumptions, but on obervations about the data.</p>
<p>Shannon studied theoretical limits for compression and transimission rates for recovering data.<br>Shannon Game:</p>
<pre><code>The Present of the United States is Barack ...

The best web search engine is ...

Mary was ...
</code></pre><p>Information content of a message is a function of how predictable it is.</p>
<p>Let $p_i$ be the probability of message $i$. The number of bits needed to encode $i$ is $-log_2 p_i$.</p>
<p>Information Entropy: the entropy of a message is the expected(minimum) number of bits needed to encode it.</p>
<p>$Entropy = H(p) = -\sum{i=1}{n} p_i log_2 p_i$</p>
<ul>
<li>unknown $p_i$</li>
<li>algorithm to compute</li>
</ul>
<h5 id="Huffman_Codes"><a href="#Huffman_Codes" class="headerlink" title="Huffman Codes"></a>Huffman Codes</h5><ul>
<li>gather probabilities for symbols (characters, words, or a mix)</li>
<li>build a tree</li>
<li><ul>
<li>get 2 least frequent symbols/nodes, join with a parent node.</li>
</ul>
</li>
<li><ul>
<li>lable least probable branch 0; label other branch 1.</li>
</ul>
</li>
<li><ul>
<li>continue until the tree contains all nodes and symbols/labels.</li>
</ul>
</li>
<li>the path to a leaf indicates its code. (binary code)</li>
<li>frequent symbols are near the root, giving them short codes.</li>
<li>less frequent symbols are deeper, giving them longer codes.</li>
</ul>
<p>p(01) &gt; p(00)</p>
<p><strong>Drawback</strong></p>
<ul>
<li>many codes are not assigned to any symbol, limiting the amount of compression possible.</li>
<li>looking up codes is somewhat inefficient. the decoder must store the entire tree.</li>
</ul>
<h5 id="Lempel-Ziv"><a href="#Lempel-Ziv" class="headerlink" title="Lempel-Ziv"></a>Lempel-Ziv</h5><p>use the text already encountered to build the dictionary.no need to store dictionary, encoder and decoder automatically build the dictionary on the fly.</p>
<p><strong>Lempel-Ziv</strong>:<br>Assume, there are n bins, for each bin, the encoded bit is $log(n)+1$.</p>
<p><strong>Improved Lempel-Ziv</strong>:</p>
<p>Change prefix bin number to the offset between prefix bin and current bin. Therefore, for bin n, the encoded bit is ceiling(log(n))+1.</p>
<h4 id="Text_Stastics"><a href="#Text_Stastics" class="headerlink" title="Text Stastics"></a>Text Stastics</h4><p>Retrieval models and ranking algorithms heavily depend on statistical properties of words, like important words occur often in documents but are not high frequency in collection. And many stastical characteristics of word occurrences are predictable, so text stastics are neccessary to take into account.</p>
<h5 id="Zipf_u2019s_Law"><a href="#Zipf_u2019s_Law" class="headerlink" title="Zipf’s Law"></a>Zipf’s Law</h5><p>Zipf’s law is actually a power law, it describes the relationship between word frequency and its frequency rank.</p>
<p>Assume words in corpus are ranked in order of decreasing frequency. rank(r) of a word times its frequency (f) is approximately a constant (k). i.e. $r.f ~= k, r.P_r ~= c$ where $P_r$ is probability of word occurrence and $c ~= 0.1$ for English.</p>
<p>Q: What is the proportion of words with a given frequency?</p>
<p>A: Proportion with frequency n is 1/n(n+1)</p>
<p>$R_n = k/n$</p>
<p>Number of words with frequency n is $r_n - r_n+1 = l/n - k/(n+1) = k/n(n+1)$</p>
<h5 id="Heap_u2019s_Law"><a href="#Heap_u2019s_Law" class="headerlink" title="Heap’s Law"></a>Heap’s Law</h5><p>How does the size of the overall vocabulary (V) grow with the size of corpus (N)?<br>$V = K N^{\beta} (0&lt;\beta&lt;1)$ where $K \in (10,100), \beta \in (0.4,0.6)$</p>
<p>This can be derived from Zipf’s law by assuming documents are generated by randomly sampling words from a Zipfian distribution。</p>
<h3 id="Retrieval_Models-1"><a href="#Retrieval_Models-1" class="headerlink" title="Retrieval Models"></a>Retrieval Models</h3><p><strong>Retrieval Models</strong>:</p>
<ul>
<li>Boolean</li>
<li><ul>
<li>Basic Boolean</li>
</ul>
</li>
<li><ul>
<li>Extended Boolean Model</li>
</ul>
</li>
<li>Vector Space Model</li>
<li>Probabilistic Models</li>
<li><ul>
<li>Basic Probabilistic model</li>
</ul>
</li>
<li><ul>
<li>Two Poisson model - BM25    Okapi</li>
</ul>
</li>
<li><ul>
<li>Bayesian inference networks        Indri</li>
</ul>
</li>
<li><ul>
<li>Statistical Language Models        Lemur</li>
</ul>
</li>
<li><ul>
<li>Portfolio Retrieval</li>
</ul>
</li>
<li>Citation Analysis Models</li>
<li><ul>
<li>Hubs &amp; Authorites    CLEVER by IBM</li>
</ul>
</li>
<li><ul>
<li>PageRank    Google</li>
</ul>
</li>
</ul>
<h4 id="Boolean_Retrival"><a href="#Boolean_Retrival" class="headerlink" title="Boolean Retrival"></a>Boolean Retrival</h4><p>Boolean model uses boolean expression to do the exact match.</p>
<ul>
<li>pros: works great if you know your goal, structured queries, simple to program, complete expressiveness</li>
<li>cons: unintuitive, often misunderstood, either too precise or too loose, unordered output so have to examine all output</li>
</ul>
<h4 id="Ranked_Boolean_Retrieval"><a href="#Ranked_Boolean_Retrieval" class="headerlink" title="Ranked Boolean Retrieval"></a>Ranked Boolean Retrieval</h4><p>Matching documents are ranked by frequency of query terms. A document term weight is how often a term occurs in a document - may be normalized. </p>
<ul>
<li>AND weight: minimum of argument weights</li>
<li>OR weight: maximum of argument weights</li>
<li>and, sum of all argument weights</li>
</ul>
<h3 id="Cloud_Computing"><a href="#Cloud_Computing" class="headerlink" title="Cloud Computing"></a>Cloud Computing</h3><h4 id="GFS"><a href="#GFS" class="headerlink" title="GFS"></a>GFS</h4><p>Google File System, using TCP. </p>
<h4 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h4><p>pioneer in C++ by Google.</p>
<p>Hadoop -&gt; Java version</p>
<p>MapReduce Programming Model, the data structure is key-value dictionary. The map function is:</p>
<p> $(K_in,V_in) \rightarrow list(K_inter,V_inter)$</p>
<p> reduce function:</p>
<p> $(K_inter, list(V_inter)) \rightarrow list(K_out,V_out)$</p>
<p>Each word has a hashcode, the task for different reducer can be set to some hashcode boundtry.</p>
<p>Optimisation, in mapper, there is a combiner works as a reducer to summary duplicate words in a mapper.</p>

      
    </div>

    <div>
      
        
      
    </div>

    <footer class="post-footer">
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2015/01/17/math-caculus/" rel="next" title="Calculus">
                <i class="fa fa-chevron-left"></i> Calculus
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2015/02/07/algo-compression-algorithm/" rel="prev" title="Compression Algorithm">
                Compression Algorithm <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/figures/me.png"
               alt="Lingxi Chen" />
          <p class="site-author-name" itemprop="name">Lingxi Chen</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/">
              <span class="site-state-item-count">37</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>
          
          
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">categories</span>
              
            </div>
          

          
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">21</span>
                <span class="site-state-item-name">tags</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        <div class="links-of-author motion-element">
          
        </div>

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc-indicator-top post-toc-indicator">
            <i class="fa fa-angle-double-up"></i>
          </div>
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Evaluation"><span class="nav-number">1.1.</span> <span class="nav-text">Evaluation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Retrieval_Models"><span class="nav-number">1.2.</span> <span class="nav-text">Retrieval Models</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Exact_Matching_3A_data_retrieval"><span class="nav-number">1.2.1.</span> <span class="nav-text">Exact Matching: data retrieval</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Best_Match/Rank_Retrieval"><span class="nav-number">1.2.2.</span> <span class="nav-text">Best Match/Rank Retrieval</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Boolean"><span class="nav-number">1.2.3.</span> <span class="nav-text">Boolean</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Extended_Boolean"><span class="nav-number">1.2.4.</span> <span class="nav-text">Extended Boolean</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#TF_IDF_Term_weighting"><span class="nav-number">1.2.5.</span> <span class="nav-text">TF IDF Term weighting</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Vector_Space_Model"><span class="nav-number">1.2.6.</span> <span class="nav-text">Vector Space Model</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Basic_Probabilistic_Model"><span class="nav-number">1.2.7.</span> <span class="nav-text">Basic Probabilistic Model</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Two_Poisson_Mode_-_BM25"><span class="nav-number">1.2.8.</span> <span class="nav-text">Two Poisson Mode - BM25</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Bayesian_Inference_Networks"><span class="nav-number">1.2.9.</span> <span class="nav-text">Bayesian Inference Networks</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Statistical_Language_Models"><span class="nav-number">1.2.10.</span> <span class="nav-text">Statistical Language Models</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Portfolio_Retrieval"><span class="nav-number">1.2.11.</span> <span class="nav-text">Portfolio Retrieval</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Citation_Analysis_Models"><span class="nav-number">1.2.12.</span> <span class="nav-text">Citation Analysis Models</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Web_Serach_via_Link_Analysis"><span class="nav-number">2.</span> <span class="nav-text">Web Serach via Link Analysis</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Relevance_Rank"><span class="nav-number">2.1.</span> <span class="nav-text">Relevance Rank</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PageRank"><span class="nav-number">2.2.</span> <span class="nav-text">PageRank</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HITS"><span class="nav-number">2.3.</span> <span class="nav-text">HITS</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Text_Procesing_and_Indexing"><span class="nav-number">3.</span> <span class="nav-text">Text Procesing and Indexing</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Text_Acquisition_3A_Web_Crawler"><span class="nav-number">3.1.</span> <span class="nav-text">Text Acquisition: Web Crawler</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Text_Transformation_3AProcessing_Text"><span class="nav-number">3.2.</span> <span class="nav-text">Text Transformation:Processing Text</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Stopping"><span class="nav-number">3.2.1.</span> <span class="nav-text">Stopping</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Stemming"><span class="nav-number">3.2.2.</span> <span class="nav-text">Stemming</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Link_Analysis"><span class="nav-number">3.2.3.</span> <span class="nav-text">Link Analysis</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Index_Creation"><span class="nav-number">3.3.</span> <span class="nav-text">Index Creation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Compression"><span class="nav-number">3.4.</span> <span class="nav-text">Compression</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Entropy"><span class="nav-number">3.4.1.</span> <span class="nav-text">Entropy</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Huffman_Codes"><span class="nav-number">3.4.2.</span> <span class="nav-text">Huffman Codes</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Lempel-Ziv"><span class="nav-number">3.4.3.</span> <span class="nav-text">Lempel-Ziv</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Text_Stastics"><span class="nav-number">3.5.</span> <span class="nav-text">Text Stastics</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Zipf_u2019s_Law"><span class="nav-number">3.5.1.</span> <span class="nav-text">Zipf’s Law</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Heap_u2019s_Law"><span class="nav-number">3.5.2.</span> <span class="nav-text">Heap’s Law</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Retrieval_Models-1"><span class="nav-number">4.</span> <span class="nav-text">Retrieval Models</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Boolean_Retrival"><span class="nav-number">4.1.</span> <span class="nav-text">Boolean Retrival</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Ranked_Boolean_Retrieval"><span class="nav-number">4.2.</span> <span class="nav-text">Ranked Boolean Retrieval</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cloud_Computing"><span class="nav-number">5.</span> <span class="nav-text">Cloud Computing</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#GFS"><span class="nav-number">5.1.</span> <span class="nav-text">GFS</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MapReduce"><span class="nav-number">5.2.</span> <span class="nav-text">MapReduce</span></a></li></ol></li></ol></div>
            
          </div>
          <div class="post-toc-indicator-bottom post-toc-indicator">
            <i class="fa fa-angle-double-down"></i>
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Lingxi Chen</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="http://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>



      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  


  




<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=0.5.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=0.5.0"></script>



  
  

  
  
<script type="text/javascript" src="/js/src/scrollspy.js?v=0.5.0"></script>

<script type="text/javascript" id="sidebar.toc.highlight">
  $(document).ready(function () {
    var tocSelector = '.post-toc';
    var $tocSelector = $(tocSelector);
    var activeCurrentSelector = '.active-current';

    $tocSelector
      .on('activate.bs.scrollspy', function () {
        var $currentActiveElement = $(tocSelector + ' .active').last();

        removeCurrentActiveClass();
        $currentActiveElement.addClass('active-current');

        $tocSelector[0].scrollTop = $currentActiveElement.position().top;
      })
      .on('clear.bs.scrollspy', function () {
        removeCurrentActiveClass();
      });

    function removeCurrentActiveClass () {
      $(tocSelector + ' ' + activeCurrentSelector)
        .removeClass(activeCurrentSelector.substring(1));
    }

    function processTOC () {
      getTOCMaxHeight();
      toggleTOCOverflowIndicators();
    }

    function getTOCMaxHeight () {
      var height = $('.sidebar').height() -
                   $tocSelector.position().top -
                   $('.post-toc-indicator-bottom').height();

      $tocSelector.css('height', height);

      return height;
    }

    function toggleTOCOverflowIndicators () {
      tocOverflowIndicator(
        '.post-toc-indicator-top',
        $tocSelector.scrollTop() > 0 ? 'show' : 'hide'
      );

      tocOverflowIndicator(
        '.post-toc-indicator-bottom',
        $tocSelector.scrollTop() >= $tocSelector.find('ol').height() - $tocSelector.height() ? 'hide' : 'show'
      )
    }

    $(document).on('sidebar.motion.complete', function () {
      processTOC();
    });

    $('body').scrollspy({ target: tocSelector });
    $(window).on('resize', function () {
      if ( $('.sidebar').hasClass('sidebar-active') ) {
        processTOC();
      }
    });

    onScroll($tocSelector);

    function onScroll (element) {
      element.on('mousewheel DOMMouseScroll', function (event) {
          var oe = event.originalEvent;
          var delta = oe.wheelDelta || -oe.detail;

          this.scrollTop += ( delta < 0 ? 1 : -1 ) * 30;
          event.preventDefault();

          toggleTOCOverflowIndicators();
      });
    }

    function tocOverflowIndicator (indicator, action) {
      var $indicator = $(indicator);
      var opacity = action === 'show' ? 1 : 0;
      $indicator.velocity ?
        $indicator.velocity('stop').velocity({
          opacity: opacity
        }, { duration: 100 }) :
        $indicator.stop().animate({
          opacity: opacity
        }, 100);
    }

  });
</script>

<script type="text/javascript" id="sidebar.nav">
  $(document).ready(function () {
    var html = $('html');
    var TAB_ANIMATE_DURATION = 200;
    var hasVelocity = $.isFunction(html.velocity);

    $('.sidebar-nav li').on('click', function () {
      var item = $(this);
      var activeTabClassName = 'sidebar-nav-active';
      var activePanelClassName = 'sidebar-panel-active';
      if (item.hasClass(activeTabClassName)) {
        return;
      }

      var currentTarget = $('.' + activePanelClassName);
      var target = $('.' + item.data('target'));

      hasVelocity ?
        currentTarget.velocity('transition.slideUpOut', TAB_ANIMATE_DURATION, function () {
          target
            .velocity('stop')
            .velocity('transition.slideDownIn', TAB_ANIMATE_DURATION)
            .addClass(activePanelClassName);
        }) :
        currentTarget.animate({ opacity: 0 }, TAB_ANIMATE_DURATION, function () {
          currentTarget.hide();
          target
            .stop()
            .css({'opacity': 0, 'display': 'block'})
            .animate({ opacity: 1 }, TAB_ANIMATE_DURATION, function () {
              currentTarget.removeClass(activePanelClassName);
              target.addClass(activePanelClassName);
            });
        });

      item.siblings().removeClass(activeTabClassName);
      item.addClass(activeTabClassName);
    });

    $('.post-toc a').on('click', function (e) {
      e.preventDefault();
      var targetSelector = NexT.utils.escapeSelector(this.getAttribute('href'));
      var offset = $(targetSelector).offset().top;
      hasVelocity ?
        html.velocity('stop').velocity('scroll', {
          offset: offset  + 'px',
          mobileHA: false
        }) :
        $('html, body').stop().animate({
          scrollTop: offset
        }, 500);
    });

    // Expand sidebar on post detail page by default, when post has a toc.
    NexT.motion.middleWares.sidebar = function () {
      var $tocContent = $('.post-toc-content');

      if (CONFIG.scheme !== 'Pisces' && (CONFIG.sidebar.display === 'post' || CONFIG.sidebar.display === 'always')) {
        if ($tocContent.length > 0 && $tocContent.html().trim().length > 0) {
          NexT.utils.displaySidebar();
        }
      }
    };
  });
</script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=0.5.0"></script>



  



  



  
  
  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>

  
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  


</body>
</html>
